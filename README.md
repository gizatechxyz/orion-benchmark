# Orion Model Benchmarking

In this repository you can find a set of benchmarkings with different model architectures where `neural-processor` and `ONNX Runtime` is used to save and quantize the models. After this process we can send the generated models to Giza Transpiler for the Cairo conversion.